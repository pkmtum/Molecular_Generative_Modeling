{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/sven/workspace/idp_generative_modeling/notebooks/property_predictor.ipynb Cell 1\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.162.152.95/home/sven/workspace/idp_generative_modeling/notebooks/property_predictor.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.162.152.95/home/sven/workspace/idp_generative_modeling/notebooks/property_predictor.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch_geometric\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mloader\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.162.152.95/home/sven/workspace/idp_generative_modeling/notebooks/property_predictor.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m SelectQM9TargetProperties, create_qm9_data_split, SelectQM9NodeFeatures\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.162.152.95/home/sven/workspace/idp_generative_modeling/notebooks/property_predictor.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.162.152.95/home/sven/workspace/idp_generative_modeling/notebooks/property_predictor.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(device)\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from torch_geometric.datasets import QM9\n",
    "import torch_geometric.transforms as T\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from data_utils import SelectQM9TargetProperties, create_qm9_data_split, SelectQM9NodeFeatures\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "transform = T.Compose([\n",
    "    SelectQM9TargetProperties(properties=[\"homo\", \"lumo\"]),\n",
    "    SelectQM9NodeFeatures(features=[\"atom_type\"]),\n",
    "    T.ToDevice(device=device)\n",
    "])\n",
    "\n",
    "dataset = QM9(root=\"./data\", transform=transform)\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = create_qm9_data_split(dataset=dataset)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "dataloaders = {\n",
    "    \"train_single\": DataLoader(train_dataset[:1], batch_size=batch_size, shuffle=True),\n",
    "    \"train_tiny\": DataLoader(train_dataset[:16], batch_size=batch_size, shuffle=True),\n",
    "    \"train_small\": DataLoader(train_dataset[:4096], batch_size=batch_size, shuffle=True),\n",
    "    \"train\": DataLoader(train_dataset, batch_size=batch_size, shuffle=True),\n",
    "\n",
    "    \"val_tiny\": DataLoader(val_dataset[:4], batch_size=batch_size, shuffle=False),\n",
    "    \"val_small\": DataLoader(val_dataset[:512], batch_size=batch_size, shuffle=False),\n",
    "    \"val\": DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "}\n",
    "num_node_feature = dataset.num_node_features\n",
    "num_targets = dataset.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features: int, num_targets: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        conv_features = 32\n",
    "\n",
    "        self.conv1 = GCNConv(num_node_features, conv_features)\n",
    "        self.conv2 = GCNConv(conv_features, conv_features)\n",
    "        self.conv3 = GCNConv(conv_features, conv_features)\n",
    "        self.fc1 = nn.Linear(conv_features, conv_features)\n",
    "        self.fc2 = nn.Linear(conv_features, num_targets)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 100%|██████████| 818/818 [00:42<00:00, 19.40it/s]\n",
      "Epoch 1 Validation: 100%|██████████| 103/103 [00:05<00:00, 17.47it/s]\n",
      "Epoch 2 Training: 100%|██████████| 818/818 [00:30<00:00, 26.62it/s]\n",
      "Epoch 3 Training: 100%|██████████| 818/818 [00:30<00:00, 26.72it/s]\n",
      "Epoch 3 Validation: 100%|██████████| 103/103 [00:03<00:00, 29.20it/s]\n",
      "Epoch 4 Training: 100%|██████████| 818/818 [00:31<00:00, 25.98it/s]\n",
      "Epoch 5 Training: 100%|██████████| 818/818 [00:30<00:00, 26.75it/s]\n",
      "Epoch 5 Validation: 100%|██████████| 103/103 [00:03<00:00, 28.74it/s]\n",
      "Epoch 6 Training: 100%|██████████| 818/818 [00:31<00:00, 25.94it/s]\n",
      "Epoch 7 Training: 100%|██████████| 818/818 [00:30<00:00, 26.87it/s]\n",
      "Epoch 7 Validation: 100%|██████████| 103/103 [00:03<00:00, 29.05it/s]\n",
      "Epoch 8 Training: 100%|██████████| 818/818 [00:30<00:00, 26.58it/s]\n",
      "Epoch 9 Training: 100%|██████████| 818/818 [00:30<00:00, 26.52it/s]\n",
      "Epoch 9 Validation: 100%|██████████| 103/103 [00:03<00:00, 29.39it/s]\n",
      "Epoch 10 Training: 100%|██████████| 818/818 [00:31<00:00, 26.31it/s]\n",
      "Epoch 11 Training: 100%|██████████| 818/818 [00:30<00:00, 26.39it/s]\n",
      "Epoch 11 Validation: 100%|██████████| 103/103 [00:03<00:00, 29.57it/s]\n",
      "Epoch 12 Training: 100%|██████████| 818/818 [00:31<00:00, 26.16it/s]\n",
      "Epoch 13 Training: 100%|██████████| 818/818 [00:30<00:00, 26.62it/s]\n",
      "Epoch 13 Validation: 100%|██████████| 103/103 [00:03<00:00, 28.93it/s]\n",
      "Epoch 14 Training: 100%|██████████| 818/818 [00:30<00:00, 26.73it/s]\n",
      "Epoch 15 Training: 100%|██████████| 818/818 [00:31<00:00, 26.09it/s]\n",
      "Epoch 15 Validation: 100%|██████████| 103/103 [00:03<00:00, 29.24it/s]\n",
      "Epoch 16 Training: 100%|██████████| 818/818 [00:30<00:00, 26.70it/s]\n",
      "Epoch 17 Training: 100%|██████████| 818/818 [00:30<00:00, 26.65it/s]\n",
      "Epoch 17 Validation: 100%|██████████| 103/103 [00:03<00:00, 28.74it/s]\n",
      "Epoch 18 Training: 100%|██████████| 818/818 [00:31<00:00, 26.20it/s]\n",
      "Epoch 19 Training: 100%|██████████| 818/818 [00:30<00:00, 26.67it/s]\n",
      "Epoch 19 Validation: 100%|██████████| 103/103 [00:03<00:00, 29.21it/s]\n",
      "Epoch 20 Training: 100%|██████████| 818/818 [00:30<00:00, 26.56it/s]\n",
      "Epoch 21 Training: 100%|██████████| 818/818 [00:31<00:00, 25.94it/s]\n",
      "Epoch 21 Validation: 100%|██████████| 103/103 [00:03<00:00, 29.43it/s]\n",
      "Epoch 22 Training: 100%|██████████| 818/818 [00:30<00:00, 26.65it/s]\n",
      "Epoch 23 Training: 100%|██████████| 818/818 [00:30<00:00, 27.00it/s]\n",
      "Epoch 23 Validation: 100%|██████████| 103/103 [00:03<00:00, 29.48it/s]\n",
      "Epoch 24 Training: 100%|██████████| 818/818 [00:31<00:00, 25.88it/s]\n",
      "Epoch 25 Training:  15%|█▍        | 122/818 [00:04<00:25, 27.00it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/sven/workspace/idp_generative_modeling/torch_geo_qm9.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.162.152.95/home/sven/workspace/idp_generative_modeling/torch_geo_qm9.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.162.152.95/home/sven/workspace/idp_generative_modeling/torch_geo_qm9.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m epoch_train_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.162.152.95/home/sven/workspace/idp_generative_modeling/torch_geo_qm9.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mfor\u001b[39;49;00m batch \u001b[39min\u001b[39;49;00m tqdm(train_loader, desc\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mEpoch \u001b[39;49m\u001b[39m{\u001b[39;49;00mepoch\u001b[39m \u001b[39;49m\u001b[39m+\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m Training\u001b[39;49m\u001b[39m\"\u001b[39;49m):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.162.152.95/home/sven/workspace/idp_generative_modeling/torch_geo_qm9.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m     optimizer\u001b[39m.\u001b[39;49mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.162.152.95/home/sven/workspace/idp_generative_modeling/torch_geo_qm9.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m     model_output \u001b[39m=\u001b[39;49m model(batch)\n",
      "File \u001b[0;32m~/anaconda3/envs/idp/lib/python3.11/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[39mfor\u001b[39;49;00m obj \u001b[39min\u001b[39;49;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[39myield\u001b[39;49;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/idp/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/idp/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/idp/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset, \u001b[39m\"\u001b[39m\u001b[39m__getitems__\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/idp/lib/python3.11/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m indices])  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m indices]\n",
      "File \u001b[0;32m~/anaconda3/envs/idp/lib/python3.11/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m indices])  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/anaconda3/envs/idp/lib/python3.11/site-packages/torch_geometric/data/dataset.py:264\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39misinstance\u001b[39m(idx, (\u001b[39mint\u001b[39m, np\u001b[39m.\u001b[39minteger))\n\u001b[1;32m    260\u001b[0m         \u001b[39mor\u001b[39;00m (\u001b[39misinstance\u001b[39m(idx, Tensor) \u001b[39mand\u001b[39;00m idx\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[1;32m    261\u001b[0m         \u001b[39mor\u001b[39;00m (\u001b[39misinstance\u001b[39m(idx, np\u001b[39m.\u001b[39mndarray) \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39misscalar(idx))):\n\u001b[1;32m    263\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices()[idx])\n\u001b[0;32m--> 264\u001b[0m     data \u001b[39m=\u001b[39m data \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(data)\n\u001b[1;32m    265\u001b[0m     \u001b[39mreturn\u001b[39;00m data\n\u001b[1;32m    267\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/idp/lib/python3.11/site-packages/torch_geometric/transforms/base_transform.py:32\u001b[0m, in \u001b[0;36mBaseTransform.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, data: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m     31\u001b[0m     \u001b[39m# Shallow-copy the data so that we prevent in-place data modification.\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(copy\u001b[39m.\u001b[39;49mcopy(data))\n",
      "File \u001b[0;32m~/anaconda3/envs/idp/lib/python3.11/site-packages/torch_geometric/transforms/compose.py:24\u001b[0m, in \u001b[0;36mCompose.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     22\u001b[0m         data \u001b[39m=\u001b[39m [transform(d) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m data]\n\u001b[1;32m     23\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 24\u001b[0m         data \u001b[39m=\u001b[39m transform(data)\n\u001b[1;32m     25\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/idp/lib/python3.11/site-packages/torch_geometric/transforms/base_transform.py:32\u001b[0m, in \u001b[0;36mBaseTransform.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, data: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m     31\u001b[0m     \u001b[39m# Shallow-copy the data so that we prevent in-place data modification.\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(copy\u001b[39m.\u001b[39;49mcopy(data))\n",
      "File \u001b[0;32m~/anaconda3/envs/idp/lib/python3.11/site-packages/torch_geometric/transforms/to_device.py:36\u001b[0m, in \u001b[0;36mToDevice.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m     33\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     34\u001b[0m     data: Union[Data, HeteroData],\n\u001b[1;32m     35\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[Data, HeteroData]:\n\u001b[0;32m---> 36\u001b[0m     \u001b[39mreturn\u001b[39;00m data\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice, \u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattrs,\n\u001b[1;32m     37\u001b[0m                    non_blocking\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnon_blocking)\n",
      "File \u001b[0;32m~/anaconda3/envs/idp/lib/python3.11/site-packages/torch_geometric/data/data.py:297\u001b[0m, in \u001b[0;36mBaseData.to\u001b[0;34m(self, device, non_blocking, *args)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto\u001b[39m(\u001b[39mself\u001b[39m, device: Union[\u001b[39mint\u001b[39m, \u001b[39mstr\u001b[39m], \u001b[39m*\u001b[39margs: \u001b[39mstr\u001b[39m,\n\u001b[1;32m    294\u001b[0m        non_blocking: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    295\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[39m    only the ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 297\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\n\u001b[1;32m    298\u001b[0m         \u001b[39mlambda\u001b[39;49;00m x: x\u001b[39m.\u001b[39;49mto(device\u001b[39m=\u001b[39;49mdevice, non_blocking\u001b[39m=\u001b[39;49mnon_blocking), \u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/anaconda3/envs/idp/lib/python3.11/site-packages/torch_geometric/data/data.py:280\u001b[0m, in \u001b[0;36mBaseData.apply\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[39mthe ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[39mfor\u001b[39;00m store \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstores:\n\u001b[0;32m--> 280\u001b[0m     store\u001b[39m.\u001b[39;49mapply(func, \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    281\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/idp/lib/python3.11/site-packages/torch_geometric/data/storage.py:191\u001b[0m, in \u001b[0;36mBaseStorage.apply\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[39mthe ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems(\u001b[39m*\u001b[39margs):\n\u001b[0;32m--> 191\u001b[0m     \u001b[39mself\u001b[39m[key] \u001b[39m=\u001b[39m recursive_apply(value, func)\n\u001b[1;32m    192\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/idp/lib/python3.11/site-packages/torch_geometric/data/storage.py:743\u001b[0m, in \u001b[0;36mrecursive_apply\u001b[0;34m(data, func)\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrecursive_apply\u001b[39m(data: Any, func: Callable) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    742\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, Tensor):\n\u001b[0;32m--> 743\u001b[0m         \u001b[39mreturn\u001b[39;00m func(data)\n\u001b[1;32m    744\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mrnn\u001b[39m.\u001b[39mPackedSequence):\n\u001b[1;32m    745\u001b[0m         \u001b[39mreturn\u001b[39;00m func(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/idp/lib/python3.11/site-packages/torch_geometric/data/data.py:298\u001b[0m, in \u001b[0;36mBaseData.to.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto\u001b[39m(\u001b[39mself\u001b[39m, device: Union[\u001b[39mint\u001b[39m, \u001b[39mstr\u001b[39m], \u001b[39m*\u001b[39margs: \u001b[39mstr\u001b[39m,\n\u001b[1;32m    294\u001b[0m        non_blocking: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    295\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[39m    only the ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[1;32m    297\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply(\n\u001b[0;32m--> 298\u001b[0m         \u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39;49mto(device\u001b[39m=\u001b[39;49mdevice, non_blocking\u001b[39m=\u001b[39;49mnon_blocking), \u001b[39m*\u001b[39margs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "from torchmetrics import MeanAbsoluteError\n",
    "\n",
    "model = GCN(num_node_features=num_node_feature, num_targets=num_targets).to(device=device)\n",
    "\n",
    "learning_rate = 5e-4\n",
    "epochs = 100\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_function = nn.MSELoss()\n",
    "metric_function = MeanAbsoluteError().to(device=device)\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "train_loader = dataloaders[\"train\"]\n",
    "val_loader = dataloaders[\"val\"]\n",
    "\n",
    "val_interval = 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    epoch_train_loss = 0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1} Training\"):\n",
    "        optimizer.zero_grad()\n",
    "        model_output = model(batch)\n",
    "        loss = loss_function(model_output, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_train_loss += loss.item()\n",
    "\n",
    "    epoch_train_loss /= len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    if epoch % val_interval == 0:\n",
    "        model.eval()\n",
    "        epoch_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            epoch_metric = 0\n",
    "            for batch in tqdm(val_loader, desc=f\"Epoch {epoch + 1} Validation\"):\n",
    "                model_output = model(batch)\n",
    "                loss = loss_function(model_output, batch.y)\n",
    "                \n",
    "                epoch_val_loss += loss.item()\n",
    "                epoch_metric += metric_function(model_output, batch.y)  \n",
    "            \n",
    "            epoch_val_loss /= len(val_loader)\n",
    "            epoch_metric /= len(val_loader)\n",
    "        \n",
    "        writer.add_scalar(\"Metric\", epoch_metric, epoch)\n",
    "        writer.add_scalars(\"Loss\", {\"Validation\": epoch_val_loss}, epoch)\n",
    "\n",
    "    writer.add_scalars(\"Loss\", {\"Training\": epoch_train_loss}, epoch)\n",
    "\n",
    "# TODO: validate every n iterations with random validation subset\n",
    "# TODO: add baseline mean prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
