{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import itertools\n",
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch_geometric.datasets import QM9\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from rdkit import RDLogger\n",
    "lg = RDLogger.logger()\n",
    "lg.setLevel(RDLogger.CRITICAL)\n",
    "\n",
    "from graph_vae.vae import GraphVAE\n",
    "from data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args\n",
    "include_hydrogen = False\n",
    "refresh_data_cache = True\n",
    "use_pre_transform = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sven/anaconda3/envs/idp/lib/python3.11/site-packages/torch_geometric/data/dataset.py:214: UserWarning: The `pre_transform` argument differs from the one used in the pre-processed version of this dataset. If you want to make use of another pre-processing technique, make sure to delete 'data/processed' first\n",
      "  warnings.warn(\n",
      "Processing...\n",
      "100%|██████████| 133885/133885 [04:36<00:00, 484.34it/s]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "transform_list = [\n",
    "    SelectQM9TargetProperties(properties=[\"homo\", \"lumo\"]),\n",
    "    SelectQM9NodeFeatures(features=[\"atom_type\"]),\n",
    "]\n",
    "if not include_hydrogen:\n",
    "    transform_list.append(DropQM9Hydrogen())\n",
    "\n",
    "max_num_nodes = 29 if include_hydrogen else 9\n",
    "transform_list += [\n",
    "    AddAdjacencyMatrix(max_num_nodes=max_num_nodes),\n",
    "    AddNodeAttributeMatrix(max_num_nodes=max_num_nodes),\n",
    "    AddEdgeAttributeMatrix(max_num_nodes=max_num_nodes),\n",
    "    # DropAttributes(attributes=[\"z\", \"pos\", \"idx\", \"name\"]),\n",
    "]\n",
    "\n",
    "if use_pre_transform:\n",
    "    pre_transform = T.Compose(transform_list)\n",
    "    transform = T.ToDevice(device=device)\n",
    "else:\n",
    "    pre_transform = None\n",
    "    transform = T.Compose(transform_list + [T.ToDevice(device=device)])\n",
    "\n",
    "# note: when the pre_filter or pre_transform is changed, delete the data/processed folder to update the dataset\n",
    "dataset = QM9(root=\"./data\", pre_transform=pre_transform, pre_filter=qm9_pre_filter, transform=transform)\n",
    "\n",
    "if refresh_data_cache:\n",
    "    # remove the processed files and recreate them\n",
    "    # this might be necessary when the pre_transform or the pre_filter has been updated\n",
    "    shutil.rmtree(dataset.processed_dir)\n",
    "    dataset = QM9(root=\"./data\", pre_transform=pre_transform, pre_filter=qm9_pre_filter, transform=transform)\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = create_qm9_data_split(dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    \"batch_size\": 32,\n",
    "    \"max_num_nodes\": max_num_nodes,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"adam_beta_1\": 0.5,\n",
    "    \"epochs\": 1,\n",
    "    \"num_node_features\": dataset.num_node_features,\n",
    "    \"num_edge_features\": dataset.num_edge_features,\n",
    "    \"latent_dim\": 128,  # c in the paper\n",
    "    \"kl_weight\": 1e-2,\n",
    "    \"include_hydrogen\": include_hydrogen,\n",
    "}\n",
    "in_checkpoint = None\n",
    "train_sample_limit = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = hparams[\"batch_size\"]\n",
    "\n",
    "dataloaders = {\n",
    "    \"val\": DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "}\n",
    "\n",
    "if train_sample_limit is not None:\n",
    "    dataloaders[\"train\"] = DataLoader(train_dataset[:train_sample_limit], batch_size=batch_size, shuffle=True)\n",
    "else:\n",
    "    dataloaders[\"train\"] = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_subset_count = 32\n",
    "dataloaders[\"val_subsets\"] = create_validation_subset_loaders(validation_dataset=val_dataset, subset_count=32, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training:   0%|          | 0/3202 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 100%|██████████| 3202/3202 [01:30<00:00, 35.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# create checkpoint dir and unique filename\n",
    "os.makedirs(\"./checkpoints/\", exist_ok=True)\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "out_checkpoint = f\"./checkpoints/graph_vae_{timestamp}.pt\"\n",
    "\n",
    "# setup model and optimizer\n",
    "graph_vae_model = GraphVAE(hparams=hparams).to(device=device)\n",
    "optimizer = torch.optim.Adam(\n",
    "    graph_vae_model.parameters(),\n",
    "    lr=hparams[\"learning_rate\"],\n",
    "    betas=(hparams[\"adam_beta_1\"], 0.999)\n",
    ")\n",
    "\n",
    "# load checkpoint\n",
    "if in_checkpoint is not None:\n",
    "    checkpoint = checkpoint = torch.load(in_checkpoint)\n",
    "    graph_vae_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "else:\n",
    "    start_epoch = 0\n",
    "\n",
    "# get dataloaders\n",
    "train_loader = dataloaders[\"train\"]\n",
    "val_subset_loader_iterator = itertools.cycle(dataloaders[\"val_subsets\"])\n",
    "\n",
    "# create tensorboard summary writer\n",
    "writer = create_tensorboard_writer(experiment_name=\"graph_vae\")\n",
    "\n",
    "validation_interval = 100\n",
    "epochs = hparams[\"epochs\"]\n",
    "\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    graph_vae_model.train()\n",
    "    for batch_index, train_batch in enumerate(tqdm(train_loader,  desc=f\"Epoch {epoch + 1} Training\")):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        train_elbo, train_recon_loss = graph_vae_model.elbo(x=train_batch)\n",
    "\n",
    "        train_loss = -train_elbo\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        iteration = len(train_loader) * epoch + batch_index\n",
    "        writer.add_scalars(\"Loss\", {\"Training\": train_loss.item()}, iteration)\n",
    "        writer.add_scalars(\"ELBO\", {\"Training\": train_elbo.item()}, iteration)\n",
    "        writer.add_scalars(\"Reconstruction Loss\", {\"Training\": train_recon_loss.item()}, iteration)\n",
    "        \n",
    "        if (iteration + 1) % validation_interval == 0 or iteration == 0:\n",
    "            graph_vae_model.eval()\n",
    "            val_loss_sum = 0\n",
    "            val_elbo_sum = 0\n",
    "\n",
    "            # Get the next subset of the validation set\n",
    "            val_loader = next(val_subset_loader_iterator)\n",
    "            with torch.no_grad():\n",
    "                for val_batch in val_loader:\n",
    "                    val_elbo, val_recon_loss = graph_vae_model.elbo(x=val_batch)\n",
    "                    val_elbo_sum += val_elbo\n",
    "                    val_loss = -val_elbo\n",
    "                    val_loss_sum += val_loss\n",
    "            \n",
    "            val_loss = val_loss_sum / len(val_loader)\n",
    "            val_elbo = val_elbo_sum / len(val_loader)\n",
    "            writer.add_scalars(\"Loss\", {\"Validation\": val_loss.item()}, iteration)\n",
    "            writer.add_scalars(\"ELBO\", {\"Validation\": val_elbo.item()}, iteration)\n",
    "            writer.add_scalars(\"Reconstruction Loss\", {\"Validation\": val_recon_loss.item()}, iteration)\n",
    "            \n",
    "            graph_vae_model.train()\n",
    "\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': graph_vae_model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        },\n",
    "        out_checkpoint\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Reconstruction Performance...:   2%|▏         | 8/401 [00:00<00:04, 79.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Reconstruction Performance...: 100%|██████████| 401/401 [00:04<00:00, 85.58it/s]\n"
     ]
    }
   ],
   "source": [
    "graph_vae_model.eval()\n",
    "\n",
    "log_hparams = hparams\n",
    "log_hparams.update({\n",
    "    \"Encoder Parameter Count\": sum(p.numel() for p in graph_vae_model.encoder.parameters() if p.requires_grad),\n",
    "    \"Decoder Parameter Count\": sum(p.numel() for p in graph_vae_model.decoder.parameters() if p.requires_grad),\n",
    "})\n",
    "\n",
    "# evaluate average reconstruction log-likelihood on validation set\n",
    "val_loader = dataloaders[\"val\"]\n",
    "val_elbo_sum = 0\n",
    "val_log_likelihood_sum = 0\n",
    "for val_batch in tqdm(val_loader, desc=\"Evaluating Reconstruction Performance...\"):\n",
    "    val_elbo, val_recon_loss = graph_vae_model.elbo(x=val_batch)\n",
    "    val_elbo_sum += val_elbo\n",
    "    val_log_likelihood_sum -= val_recon_loss\n",
    "\n",
    "metrics = dict()\n",
    "metrics.update({\n",
    "    \"ELBO\": val_elbo_sum / len(val_loader),\n",
    "    \"Log-likelihood\": val_log_likelihood_sum / len(val_loader)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting training graphs to SMILES...:   0%|          | 1/3202 [00:00<08:41,  6.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting training graphs to SMILES...: 100%|██████████| 3202/3202 [02:43<00:00, 19.53it/s]\n",
      "Generating Molecules...: 100%|██████████| 1000/1000 [00:11<00:00, 89.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# decoding quality metrics\n",
    "train_mol_smiles = set()\n",
    "for batch in tqdm(train_loader, desc=\"Converting training graphs to SMILES...\"):\n",
    "    for sample_index in range(len(batch)):\n",
    "        sample = batch[sample_index]\n",
    "        mol = graph_to_mol(data=sample, includes_h=include_hydrogen, validate=False)\n",
    "        train_mol_smiles.add(Chem.MolToSmiles(mol))\n",
    "\n",
    "num_samples = 1000\n",
    "num_valid_mols = 0\n",
    "\n",
    "generated_mol_smiles = set()\n",
    "z, x = graph_vae_model.sample(num_samples=num_samples, device=device)\n",
    "for i in tqdm(range(num_samples), \"Generating Molecules...\"):\n",
    "    sample_matrices = (x[0][i:i+1], x[1][i:i+1], x[2][i:i+1])\n",
    "    sample_graph = graph_vae_model.output_to_graph(x=sample_matrices)\n",
    "    \n",
    "    try:\n",
    "        mol = graph_to_mol(data=sample_graph, includes_h=include_hydrogen, validate=True)\n",
    "        num_valid_mols += 1\n",
    "        smiles = Chem.MolToSmiles(mol)\n",
    "        if smiles in generated_mol_smiles:\n",
    "            continue\n",
    "        generated_mol_smiles.add(Chem.MolToSmiles(mol))\n",
    "        writer.add_image('Generated', mol_to_image_tensor(mol=mol), global_step=i, dataformats=\"NCHW\")\n",
    "    except Exception as e:\n",
    "        # print(f\"Invalid molecule: {e}\")\n",
    "        # mol = graph_to_mol(data=sample_graph, includes_h=include_hydrogen, validate=False)\n",
    "        pass\n",
    "    \n",
    "non_novel_mols = train_mol_smiles.intersection(generated_mol_smiles)\n",
    "novel_mol_count = len(generated_mol_smiles) - len(non_novel_mols)\n",
    "\n",
    "metrics.update({\n",
    "    \"Validity\": num_valid_mols / num_samples,\n",
    "    \"Uniqueness\": len(generated_mol_smiles) / num_valid_mols,\n",
    "    \"Novelty\": novel_mol_count / len(generated_mol_smiles),  \n",
    "})\n",
    "log_hparams[\"checkpoint\"] = out_checkpoint\n",
    "writer.add_hparams(hparam_dict=log_hparams, metric_dict=metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
