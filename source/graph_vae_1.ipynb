{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from typing import List, Dict, Any\n",
    "import itertools\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import QM9\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.utils import to_dense_adj, dense_to_sparse, remove_self_loops\n",
    "from data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "max_num_nodes = 29\n",
    "\n",
    "# TODO: pre-transform and store matrices to disk\n",
    "transform = T.Compose([\n",
    "    SelectQM9TargetProperties(properties=[\"homo\", \"lumo\"]),\n",
    "    SelectQM9NodeFeatures(features=[\"atom_type\"]),\n",
    "    AddAdjacencyMatrix(max_num_nodes=max_num_nodes),\n",
    "    AddNodeAttributeMatrix(max_num_nodes=max_num_nodes),\n",
    "    T.ToDevice(device=device)\n",
    "])\n",
    "\n",
    "dataset = QM9(root=\"./data\", transform=transform)\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = create_qm9_data_split(dataset=dataset)\n",
    "\n",
    "num_node_features = dataset.num_node_features\n",
    "num_edge_features = dataset.num_edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, hparams: Dict[str, Any]) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # TODO: two graph convolutional layers (32 and 64 channeles) with identity connection (edge conditioned graph convolution)\n",
    "        self.conv1 = GCNConv(in_channels=hparams[\"num_node_features\"], out_channels=32)\n",
    "        self.conv2 = GCNConv(in_channels=32, out_channels=64)\n",
    "        self.fc = nn.Linear(in_features=64, out_features=128)\n",
    "\n",
    "    def forward(self, data: Data):\n",
    "        x, edge_index, batch, edge_attr = data.x, data.edge_index, data.batch, data.edge_attr\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, hparams: Dict[str, Any]) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.fcls = nn.Sequential(\n",
    "            nn.Linear(in_features=128, out_features=128),\n",
    "            nn.BatchNorm1d(num_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=256),\n",
    "            nn.BatchNorm1d(num_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256, out_features=512),\n",
    "            nn.BatchNorm1d(num_features=512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.max_num_nodes = hparams[\"max_num_nodes\"]\n",
    "        self.num_node_features = hparams[\"num_node_features\"]\n",
    "\n",
    "        # the atom graph is symmetric so we only predict the upper triangular part\n",
    "        upper_triangular_size = int(self.max_num_nodes * (self.max_num_nodes + 1) / 2)\n",
    "        self.fc_adjacency = nn.Linear(in_features=512, out_features=upper_triangular_size)\n",
    "\n",
    "        self.fc_node_features = nn.Linear(in_features=512, out_features=self.max_num_nodes * hparams[\"num_node_features\"])\n",
    "        self.fc_edge_features = nn.Linear(in_features=512, out_features=self.max_num_nodes * hparams[\"num_edge_features\"])\n",
    "        \n",
    "\n",
    "    def forward(self, z: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        x = self.fcls(z)\n",
    "        # predict upper triangular matrix including the diagonal\n",
    "        adj_triu_matrix = self.fc_adjacency(x)\n",
    "        node_features = self.fc_node_features(x)\n",
    "        edge_features = self.fc_edge_features(x)\n",
    "\n",
    "        # reshape matrices\n",
    "        node_features = node_features.view(-1, self.max_num_nodes, self.num_node_features)\n",
    "\n",
    "        return adj_triu_matrix, node_features, edge_features\n",
    "\n",
    "\n",
    "class GraphVAE(nn.Module):\n",
    "\n",
    "    def __init__(self, hparams: Dict[str, Any]) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = Encoder(hparams=hparams)\n",
    "        self.decoder = Decoder(hparams=hparams)\n",
    "\n",
    "    def forward(self, data) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        z = self.encoder(data)\n",
    "        x = self.decoder(z)\n",
    "        return x\n",
    "    \n",
    "    def reconstruction_loss(\n",
    "        self, \n",
    "        input: Tuple[torch.Tensor, torch.Tensor, torch.Tensor], \n",
    "        target: Tuple[torch.Tensor, torch.Tensor, torch.Tensor]\n",
    "    ):\n",
    "        input_adj_triu_mat, input_node_features, _ = input\n",
    "        target_adj_triu_mat, target_node_features, _ = target\n",
    "\n",
    "        # TODO: average over separately over diagonal and off-diagonal elements\n",
    "        adjacency_loss = F.binary_cross_entropy_with_logits(input=input_adj_triu_mat, target=target_adj_triu_mat)\n",
    "\n",
    "        node_logits = input_node_features.view(-1, input_node_features.size(-1))\n",
    "        node_targets = target_node_features.argmax(dim=2).view(-1)\n",
    "        node_feature_loss = F.cross_entropy(input=node_logits, target=node_targets)\n",
    "\n",
    "        return adjacency_loss + node_feature_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    \"batch_size\": 32,\n",
    "    \"max_num_nodes\": max_num_nodes,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"beta_1\": 0.5,\n",
    "    \"epochs\": 1000,\n",
    "    \"num_node_features\": num_node_features,\n",
    "    \"num_edge_features\": num_edge_features\n",
    "}\n",
    "\n",
    "# TODO: plot reconstruction\n",
    "# TODO: implement reconstruction loss adjacency\n",
    "# TODO: implement reconstruction loss node features\n",
    "# TODO: implement reconstruction loss edge features\n",
    "\n",
    "# TODO: filter chemically invalid mols from QM9 dataset\n",
    "# TODO: add kl-loss\n",
    "# TODO: implement encoder from the paper\n",
    "# TODO: graph matching\n",
    "\n",
    "batch_size = hparams[\"batch_size\"]\n",
    "dataloaders = {\n",
    "    \"train_single\": DataLoader(train_dataset[:1], batch_size=batch_size, shuffle=True),\n",
    "    \"train_tiny\": DataLoader(train_dataset[:batch_size], batch_size=batch_size, shuffle=True),\n",
    "    \"train_small\": DataLoader(train_dataset[:4096], batch_size=batch_size, shuffle=True),\n",
    "    \"train\": DataLoader(train_dataset, batch_size=batch_size, shuffle=True),\n",
    "\n",
    "    \"val\": DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "}\n",
    "\n",
    "val_subset_count = 32\n",
    "dataloaders[\"val_subsets\"] = create_validation_subset_loaders(validation_dataset=val_dataset, subset_count=32, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 100%|██████████| 1/1 [00:01<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "20\n",
      "Data(x=[20, 5], edge_index=[2, 138])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "17\n",
      "Data(x=[17, 5], edge_index=[2, 58])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "20\n",
      "Data(x=[20, 5], edge_index=[2, 48])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training: 100%|██████████| 1/1 [00:00<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "19\n",
      "Data(x=[19, 5], edge_index=[2, 34])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training: 100%|██████████| 1/1 [00:00<00:00,  8.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "19\n",
      "Data(x=[19, 5], edge_index=[2, 22])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "19\n",
      "Data(x=[19, 5], edge_index=[2, 22])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training: 100%|██████████| 1/1 [00:00<00:00,  8.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "19\n",
      "Data(x=[19, 5], edge_index=[2, 22])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Training: 100%|██████████| 1/1 [00:00<00:00,  8.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[19, 5], edge_index=[2, 22])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 Training: 100%|██████████| 1/1 [00:00<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "19\n",
      "Data(x=[19, 5], edge_index=[2, 22])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 Training: 100%|██████████| 1/1 [00:00<00:00,  8.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 22])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 Training: 100%|██████████| 1/1 [00:00<00:00,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 22])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 Training: 100%|██████████| 1/1 [00:00<00:00,  8.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 22])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 Training: 100%|██████████| 1/1 [00:00<00:00,  8.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 22])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 Training: 100%|██████████| 1/1 [00:00<00:00,  8.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 22])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 Training: 100%|██████████| 1/1 [00:00<00:00,  8.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 Training: 100%|██████████| 1/1 [00:00<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 22])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 Training: 100%|██████████| 1/1 [00:00<00:00,  8.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 22])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 Training: 100%|██████████| 1/1 [00:00<00:00,  8.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 22])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 Training: 100%|██████████| 1/1 [00:00<00:00,  7.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 22])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 Training: 100%|██████████| 1/1 [00:00<00:00,  8.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 Training: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 Training: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 Training: 100%|██████████| 1/1 [00:00<00:00,  8.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 Training: 100%|██████████| 1/1 [00:00<00:00,  8.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 Training: 100%|██████████| 1/1 [00:00<00:00,  8.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 Training: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 Training: 100%|██████████| 1/1 [00:00<00:00,  7.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 Training: 100%|██████████| 1/1 [00:00<00:00,  8.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29 Training: 100%|██████████| 1/1 [00:00<00:00,  8.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 Training: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31 Training: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32 Training: 100%|██████████| 1/1 [00:00<00:00,  7.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33 Training: 100%|██████████| 1/1 [00:00<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 26])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34 Training: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 26])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35 Training: 100%|██████████| 1/1 [00:00<00:00,  8.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 26])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36 Training: 100%|██████████| 1/1 [00:00<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 26])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37 Training: 100%|██████████| 1/1 [00:00<00:00,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 26])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38 Training: 100%|██████████| 1/1 [00:00<00:00,  7.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 26])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39 Training: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 28])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40 Training: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[18, 5], edge_index=[2, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41 Training: 100%|██████████| 1/1 [00:00<00:00,  8.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[18, 5], edge_index=[2, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42 Training: 100%|██████████| 1/1 [00:00<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43 Training: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44 Training: 100%|██████████| 1/1 [00:00<00:00,  8.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45 Training: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46 Training: 100%|██████████| 1/1 [00:00<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47 Training: 100%|██████████| 1/1 [00:00<00:00,  8.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48 Training: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49 Training: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50 Training: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51 Training: 100%|██████████| 1/1 [00:00<00:00,  7.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52 Training: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53 Training: 100%|██████████| 1/1 [00:00<00:00,  8.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54 Training: 100%|██████████| 1/1 [00:00<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55 Training: 100%|██████████| 1/1 [00:00<00:00,  8.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 34])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56 Training: 100%|██████████| 1/1 [00:00<00:00,  9.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 34])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57 Training: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 36])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58 Training: 100%|██████████| 1/1 [00:00<00:00,  8.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 36])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59 Training: 100%|██████████| 1/1 [00:00<00:00,  7.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 36])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60 Training: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 38])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61 Training: 100%|██████████| 1/1 [00:00<00:00,  8.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 38])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62 Training: 100%|██████████| 1/1 [00:00<00:00,  8.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 38])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63 Training: 100%|██████████| 1/1 [00:00<00:00,  8.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 38])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64 Training: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 38])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65 Training: 100%|██████████| 1/1 [00:00<00:00,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 38])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66 Training: 100%|██████████| 1/1 [00:00<00:00,  8.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 38])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67 Training: 100%|██████████| 1/1 [00:00<00:00,  9.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 38])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68 Training: 100%|██████████| 1/1 [00:00<00:00,  9.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 38])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69 Training: 100%|██████████| 1/1 [00:00<00:00,  8.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 38])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70 Training: 100%|██████████| 1/1 [00:00<00:00,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 36])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71 Training: 100%|██████████| 1/1 [00:00<00:00,  9.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 36])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72 Training: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 36])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73 Training: 100%|██████████| 1/1 [00:00<00:00,  8.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 34])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74 Training: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 36])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75 Training: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 36])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76 Training: 100%|██████████| 1/1 [00:00<00:00,  7.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 36])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77 Training: 100%|██████████| 1/1 [00:00<00:00,  8.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 36])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78 Training: 100%|██████████| 1/1 [00:00<00:00,  8.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 34])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79 Training: 100%|██████████| 1/1 [00:00<00:00,  9.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 34])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80 Training: 100%|██████████| 1/1 [00:00<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81 Training: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82 Training: 100%|██████████| 1/1 [00:00<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "18\n",
      "Data(x=[18, 5], edge_index=[2, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83 Training: 100%|██████████| 1/1 [00:00<00:00,  8.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "19\n",
      "Data(x=[19, 5], edge_index=[2, 30])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84 Training: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "19\n",
      "Data(x=[19, 5], edge_index=[2, 28])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85 Training: 100%|██████████| 1/1 [00:00<00:00,  7.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "19\n",
      "Data(x=[19, 5], edge_index=[2, 26])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86 Training: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "19\n",
      "Data(x=[19, 5], edge_index=[2, 24])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87 Training: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "19\n",
      "Data(x=[19, 5], edge_index=[2, 22])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88 Training: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "19\n",
      "Data(x=[19, 5], edge_index=[2, 22])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89 Training: 100%|██████████| 1/1 [00:00<00:00,  7.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "19\n",
      "Data(x=[19, 5], edge_index=[2, 22])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90 Training: 100%|██████████| 1/1 [00:00<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "19\n",
      "Data(x=[19, 5], edge_index=[2, 22])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91 Training: 100%|██████████| 1/1 [00:00<00:00,  8.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "19\n",
      "Data(x=[19, 5], edge_index=[2, 22])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92 Training: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "19\n",
      "Data(x=[19, 5], edge_index=[2, 22])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93 Training: 100%|██████████| 1/1 [00:00<00:00,  8.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "19\n",
      "Data(x=[19, 5], edge_index=[2, 22])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94 Training: 100%|██████████| 1/1 [00:00<00:00,  8.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "19\n",
      "Data(x=[19, 5], edge_index=[2, 22])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95 Training: 100%|██████████| 1/1 [00:00<00:00,  7.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "19\n",
      "Data(x=[19, 5], edge_index=[2, 22])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96 Training: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "19\n",
      "Data(x=[19, 5], edge_index=[2, 22])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97 Training: 100%|██████████| 1/1 [00:00<00:00,  8.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "19\n",
      "Data(x=[19, 5], edge_index=[2, 22])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98 Training: 100%|██████████| 1/1 [00:00<00:00,  7.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "19\n",
      "Data(x=[19, 5], edge_index=[2, 22])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99 Training: 100%|██████████| 1/1 [00:00<00:00,  7.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "19\n",
      "Data(x=[19, 5], edge_index=[2, 22])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100 Training: 100%|██████████| 1/1 [00:00<00:00,  8.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node count:\n",
      "19\n",
      "Data(x=[19, 5], edge_index=[2, 22])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 101 Training:   0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(val_subset_loader_iterator)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 38\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_prediction\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgraph_vae_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_target\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madj_triu_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/idp/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/idp/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/idp/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/idp/lib/python3.11/site-packages/torch/utils/data/dataset.py:362\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitems__\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices: List[\u001b[38;5;28mint\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[T_co]:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;66;03m# add batched sampling support when parent dataset supports it.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;66;03m# see torch.utils.data._utils.fetch._MapDatasetFetcher\u001b[39;00m\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)):\n\u001b[0;32m--> 362\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    364\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/miniconda3/envs/idp/lib/python3.11/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/idp/lib/python3.11/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/miniconda3/envs/idp/lib/python3.11/site-packages/torch_geometric/data/dataset.py:264\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, (\u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39minteger))\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, Tensor) \u001b[38;5;129;01mand\u001b[39;00m idx\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(idx))):\n\u001b[1;32m    263\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices()[idx])\n\u001b[0;32m--> 264\u001b[0m     data \u001b[38;5;241m=\u001b[39m data \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/idp/lib/python3.11/site-packages/torch_geometric/transforms/base_transform.py:32\u001b[0m, in \u001b[0;36mBaseTransform.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Shallow-copy the data so that we prevent in-place data modification.\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/idp/lib/python3.11/site-packages/torch_geometric/transforms/compose.py:24\u001b[0m, in \u001b[0;36mCompose.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     22\u001b[0m         data \u001b[38;5;241m=\u001b[39m [transform(d) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 24\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/idp/lib/python3.11/site-packages/torch_geometric/transforms/base_transform.py:32\u001b[0m, in \u001b[0;36mBaseTransform.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Shallow-copy the data so that we prevent in-place data modification.\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/idp_generative_modeling/source/data_utils.py:77\u001b[0m, in \u001b[0;36mAddAdjacencyMatrix.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     74\u001b[0m     data: Union[Data, HeteroData],\n\u001b[1;32m     75\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Data, HeteroData]:\n\u001b[1;32m     76\u001b[0m     edge_index_with_loops, _ \u001b[38;5;241m=\u001b[39m add_self_loops(edge_index\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39medge_index)\n\u001b[0;32m---> 77\u001b[0m     adj_mat \u001b[38;5;241m=\u001b[39m \u001b[43mto_dense_adj\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_index_with_loops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_num_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_num_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     data\u001b[38;5;241m.\u001b[39madj_triu_mat \u001b[38;5;241m=\u001b[39m adj_mat[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtriu_mask]\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/idp/lib/python3.11/site-packages/torch_geometric/utils/to_dense_adj.py:72\u001b[0m, in \u001b[0;36mto_dense_adj\u001b[0;34m(edge_index, batch, edge_attr, max_num_nodes, batch_size)\u001b[0m\n\u001b[1;32m     69\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(batch\u001b[38;5;241m.\u001b[39mmax()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     71\u001b[0m one \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mnew_ones(batch\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m---> 72\u001b[0m num_nodes \u001b[38;5;241m=\u001b[39m \u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m cum_nodes \u001b[38;5;241m=\u001b[39m cumsum(num_nodes)\n\u001b[1;32m     75\u001b[0m idx0 \u001b[38;5;241m=\u001b[39m batch[edge_index[\u001b[38;5;241m0\u001b[39m]]\n",
      "File \u001b[0;32m~/miniconda3/envs/idp/lib/python3.11/site-packages/torch_geometric/utils/scatter.py:60\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[1;32m     48\u001b[0m     dim_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(index\u001b[38;5;241m.\u001b[39mmax()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# For now, we maintain various different code paths, based on whether\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# the input requires gradients and whether it lays on the CPU/GPU.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# For example, `torch_scatter` is usually faster than\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# indices, but is therefore way slower in its backward implementation.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# More insights can be found in `test/utils/test_scatter.py`.\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m size \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39msize()[:dim] \u001b[38;5;241m+\u001b[39m (dim_size, ) \u001b[38;5;241m+\u001b[39m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[dim \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# For \"any\" reduction, we use regular `scatter_`:\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124many\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "graph_vae_model = GraphVAE(hparams=hparams).to(device=device)\n",
    "optimizer = torch.optim.Adam(\n",
    "    graph_vae_model.parameters(),\n",
    "    lr=hparams[\"learning_rate\"],\n",
    "    betas=(hparams[\"beta_1\"], 0.999)\n",
    ")\n",
    "epochs = hparams[\"epochs\"]\n",
    "\n",
    "train_loader = dataloaders[\"train_tiny\"]\n",
    "val_subset_loader_iterator = itertools.cycle(dataloaders[\"val_subsets\"])\n",
    "\n",
    "validation_interval = 100\n",
    "\n",
    "writer = create_tensorboard_writer(experiment_name=\"graph-vae\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    graph_vae_model.train()\n",
    "    for batch_index, train_batch in enumerate(tqdm(train_loader,  desc=f\"Epoch {epoch + 1} Training\")):\n",
    "        optimizer.zero_grad()\n",
    "        train_prediction = graph_vae_model(train_batch)\n",
    "        train_target = (train_batch.adj_triu_mat, train_batch.node_mat, ...)\n",
    "\n",
    "        loss = graph_vae_model.reconstruction_loss(input=train_prediction, target=train_target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        iteration = len(train_loader) * epoch + batch_index\n",
    "        writer.add_scalars(\"Loss\", {\"Training\": loss.item()}, iteration)\n",
    "\n",
    "        if iteration % validation_interval == 0:\n",
    "            graph_vae_model.eval()\n",
    "            val_loss_sum = 0\n",
    "\n",
    "            # Get the next subset of the validation set\n",
    "            val_loader = next(val_subset_loader_iterator)\n",
    "            with torch.no_grad():\n",
    "                for val_batch in val_loader:\n",
    "                    val_prediction = graph_vae_model(val_batch)\n",
    "                    val_target = (val_batch.adj_triu_mat, val_batch.node_mat, ...)\n",
    "                    val_loss_sum += graph_vae_model.reconstruction_loss(\n",
    "                        input=val_prediction,\n",
    "                        target=val_target\n",
    "                    )\n",
    "            \n",
    "            val_loss = val_loss_sum / len(val_loader)\n",
    "            writer.add_scalars(\"Loss\", {\"Validation\": val_loss.item()}, iteration)\n",
    "            \n",
    "            graph_vae_model.train()\n",
    "\n",
    "    # Visualization\n",
    "    # get random mol from train dataset and visualize\n",
    "    sample_index = random.randint(0, len(train_loader) * batch_size)\n",
    "    sample_index = 32\n",
    "    sample = train_dataset[sample_index]\n",
    "    # print(sample)\n",
    "    writer.add_image('Input', molecule_graph_data_to_image(sample), global_step=epoch, dataformats=\"NCHW\")\n",
    "\n",
    "    graph_vae_model.eval()\n",
    "    prediction = graph_vae_model(sample)\n",
    "\n",
    "    # convert predicted matrices into Graph\n",
    "    adj_triu_mat = torch.where(F.sigmoid(prediction[0]) > 0.5, 1.0, 0.0)[0]\n",
    "\n",
    "    n = hparams[\"max_num_nodes\"]\n",
    "    mask = torch.ones(n, n).triu() == 1\n",
    "    adj_mat = torch.zeros(n, n, device=device)\n",
    "    adj_mat[mask] = adj_triu_mat\n",
    "    diagonal = adj_mat.diagonal()\n",
    "    # create symmetric matrix\n",
    "    adj_mat = adj_mat + adj_mat.t() - torch.diag(diagonal)\n",
    "\n",
    "    invalid_node_indices = (diagonal == 0).nonzero().flatten().cpu().tolist()\n",
    "\n",
    "    edge_index, _ = dense_to_sparse(adj=adj_mat)\n",
    "    edge_index, _ = remove_self_loops(edge_index=edge_index)\n",
    "\n",
    "    # assume hydrogen for all atoms for now\n",
    "    x = torch.zeros(29, 5)\n",
    "    x[:, 0] = 1\n",
    "\n",
    "    reconstructed_sample = Data(x=x, edge_index=edge_index)\n",
    "    reconstructed_sample = remove_nodes(data=reconstructed_sample, nodes_to_remove=invalid_node_indices)\n",
    "\n",
    "    def create_edge_attr(edge_index, edge_attr_matrix):\n",
    "        # Assuming the edge_attr_matrix is ordered in the same way as the adjacency matrix\n",
    "        edge_attr = edge_attr_matrix[edge_index[0], edge_index[1]]\n",
    "        return edge_attr\n",
    "    \n",
    "    # add edge attributes\n",
    "    edge_attr = torch.zeros(reconstructed_sample.num_edges, 4)\n",
    "    # single bond for now\n",
    "    edge_attr[:, 0] = 1\n",
    "    reconstructed_sample.edge_attr = edge_attr\n",
    "    \n",
    "    writer.add_image('Reconstruction', molecule_graph_data_to_image(reconstructed_sample), global_step=epoch, dataformats=\"NCHW\")  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
